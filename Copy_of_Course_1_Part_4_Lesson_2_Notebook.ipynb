{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Course_1_Part_4_Lesson_2_Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DarinaVel/Course/blob/master/Copy_of_Course_1_Part_4_Lesson_2_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnyTxjK_GbOD",
        "colab_type": "text"
      },
      "source": [
        "# продолжаем Hello World, пример компьютерного зрения\n",
        "В предыдущем упражнении вы увидели, как создать нейронную сеть, которая выяснила проблему, которую вы пытались решить. Она показала пример явного обученного поведения. Конечно, в том случае это было немного излишним, потому что было бы проще написать функцию Y = 2x-1 напрямую, вместо того, чтобы пытаться использовать машинное обучение для изучения отношений между X и Y для фиксированного набора значений и расширения его на все значения.\n",
        "\n",
        "Но как насчет сценария, в котором написание подобных правил намного сложнее - например, проблемы с компьютерным зрением? Давайте посмотрим на сценарий, в котором мы можем распознать различные предметы одежды, обученные из набора данных, содержащего 10 различных типов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H41FYgtlHPjW",
        "colab_type": "text"
      },
      "source": [
        "## Начало программирования\n",
        "\n",
        "Начнем с нашего импорта TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3KzJyjv3rnA",
        "colab_type": "code",
        "outputId": "59fa62da-9dc1-43ad-d9db-81606f363d04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_n1U5do3u_F",
        "colab_type": "text"
      },
      "source": [
        "Данные Fashion MNIST доступны непосредственно в API наборов данных tf.keras. Вы загружаете их как здесь:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmxkHFpt31bM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuoLQQBT4E-_",
        "colab_type": "text"
      },
      "source": [
        "Вызов load_data для этого объекта даст вам два набора из двух списков, это будут обучающие и тестовые данные картинок, содержащих предметы одежды и их метки."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTdRgExe4TRB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "0fcd8718-0eea-4369-80dc-871dd87ac3c1"
      },
      "source": [
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw395ROx4f5Q",
        "colab_type": "text"
      },
      "source": [
        "Как выглядят эти значения? Давайте выведем картинку и ее метку из обучающего набора, чтобы посмотреть.\n",
        "Поэкспериментируйте с различными индексами в массиве. Например, взгляните также на индекс 42\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPc9d3gJ3jWF",
        "colab_type": "code",
        "outputId": "7fb4e7fc-88da-48e0-9afd-c83802df7101",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(test_images[0])\n",
        "print(test_labels[0])\n",
        "print(test_images[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   3   1   0   0   7   0  37   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   1   2   0  27  84\n",
            "   11   0   0   0   0   0   0 119   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  88 143\n",
            "  110   0   0   0   0  22  93 106   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   4   0  53 129 120\n",
            "  147 175 157 166 135 154 168 140   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  11 137 130 128\n",
            "  160 176 159 167 178 149 151 144   0   0]\n",
            " [  0   0   0   0   0   0   1   0   2   1   0   3   0   0 115 114 106 137\n",
            "  168 153 156 165 167 143 157 158  11   0]\n",
            " [  0   0   0   0   1   0   0   0   0   0   3   0   0  89 139  90  94 153\n",
            "  149 131 151 169 172 143 159 169  48   0]\n",
            " [  0   0   0   0   0   0   2   4   1   0   0   0  98 136 110 109 110 162\n",
            "  135 144 149 159 167 144 158 169 119   0]\n",
            " [  0   0   2   2   1   2   0   0   0   0  26 108 117  99 111 117 136 156\n",
            "  134 154 154 156 160 141 147 156 178   0]\n",
            " [  3   0   0   0   0   0   0  21  53  92 117 111 103 115 129 134 143 154\n",
            "  165 170 154 151 154 143 138 150 165  43]\n",
            " [  0   0  23  54  65  76  85 118 128 123 111 113 118 127 125 139 133 136\n",
            "  160 140 155 161 144 155 172 161 189  62]\n",
            " [  0  68  94  90 111 114 111 114 115 127 135 136 143 126 127 151 154 143\n",
            "  148 125 162 162 144 138 153 162 196  58]\n",
            " [ 70 169 129 104  98 100  94  97  98 102 108 106 119 120 129 149 156 167\n",
            "  190 190 196 198 198 187 197 189 184  36]\n",
            " [ 16 126 171 188 188 184 171 153 135 120 126 127 146 185 195 209 208 255\n",
            "  209 177 245 252 251 251 247 220 206  49]\n",
            " [  0   0   0  12  67 106 164 185 199 210 211 210 208 190 150  82   8   0\n",
            "    0   0 178 208 188 175 162 158 151  11]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/EBS/wfAkh/XIL+CnQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cbrdH225_nH",
        "colab_type": "text"
      },
      "source": [
        "Вы заметите, что все значения в числе находятся в диапазоне от 0 до 255. Если мы обучаем нейронную сеть, по разным причинам будет проще, если мы будем рассматривать все значения в диапазоне от 0 до 1, известный нам процесс **нормализация**. И, благодаря векторизации, в Python такой список легко нормализовать без циклов. Вы делаете это так:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRH19pWs6ZDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_images  = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DkO0As46lRn",
        "colab_type": "text"
      },
      "source": [
        "Теперь вам может быть интересно, почему тут 2 комплекта: обучение и тестирование - помните, мы говорили об этом во вступлении? \n",
        "Идея состоит в том, чтобы иметь 1 набор данных для обучения, а затем еще один набор данных, которого модель еще не видела ... чтобы увидеть, насколько хороша она будет в классификации значений. В конце концов, когда вы закончите, вы захотите попробовать это с данными, которые раньше не видели!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIn7S9gf62ie",
        "colab_type": "text"
      },
      "source": [
        "Давайте теперь соберем модель. Здесь довольно много новых понятий, но не волнуйтесь, вы их освоите."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mAyndG3kVlK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lUcWaiX7MFj",
        "colab_type": "text"
      },
      "source": [
        "**Sequential** - определяет ПОСЛЕДОВАТЕЛЬНОСТЬ слоев в нейронной сети\n",
        "\n",
        "**Flatten** - Помните, наши изображения были квадратными, когда вы их распечатывали? Flatten просто берет этот квадрат и превращает его в одномерный вектор.\n",
        "\n",
        "**Dense** - Добавляет слой нейронов\n",
        "\n",
        "Каждому слою нейронов требуется  **activation function**, чтобы сообщить им, что делать. Есть много вариантов, но сейчас просто используйте эти.\n",
        "\n",
        "**Relu** Фактически означает «если X>0 - возвращает X, иначе возвращает 0» - всё, что  делает эта функция активации - только передает те значения, которые больше нуля на следующий уровень в сети.\n",
        "\n",
        "**Softmax** - берет набор значений и фактически выбирает самое большое, поэтому, например, если выходные данные последнего слоя выглядят как [0,1, 0,1, 0,05, 0,1, 9,5, 0,1, 0,05, 0,05, 0,05], то после Softmax результат будет таким: [0,0,0,0,1,0,0,0,0] - цель - сэкономить много кода!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8vbMCqb9Mh6",
        "colab_type": "text"
      },
      "source": [
        "Теперь, когда модель определена, следующее, что нужно сделать - создать ее. Вы делаете это, компилируя ее с указанием оптимизатора и функции потерь, как и раньше, а затем тренируете посредством метода **model.fit**, который сопоставит ваши тренировочные данные меткам обучения - то есть, выявит взаимосвязи между обучающими данными и их фактическими метками. И в будущем, если у вас есть данные, которые похожи на обучающие данные, то модель может их классифицировать."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLMdl9aP8nQ0",
        "colab_type": "code",
        "outputId": "a92c4c57-097c-4c79-965f-088f368eb227",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "model.compile(optimizer = tf.train.AdamOptimizer(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Train on 60000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.4941 - acc: 0.8247\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 4s 71us/sample - loss: 0.3722 - acc: 0.8634\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.3322 - acc: 0.8782\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 4s 75us/sample - loss: 0.3100 - acc: 0.8855\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.2904 - acc: 0.8929\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff0a2c8e860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JJMsvSB-1UY",
        "colab_type": "text"
      },
      "source": [
        "Как только вы закончите тренировку - вы увидите значение точности в конце финальной эпохи. Она может выглядеть примерно как 0,9098. Это говорит о том, что ваша нейронная сеть на 91% точна в классификации тренировочных данных. То есть, она выяснила  шаблон совпадения между изображением и надписями, который работает в 91% случаев. Не здорово, но неплохо, учитывая, что она была тренирована только 5 эпох и закончила довольно быстро.\n",
        "Но как она будет работать с новыми данными? Вот для чего у нас есть тестовые изображения. Мы можем вызвать метод **model.evaluate**, с двумя приготовленными тестовыми наборами, и он сообщит нам об ошибке для каждой пары вектор-метка. Давайте попробуем:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzlqsEzX9s5P",
        "colab_type": "code",
        "outputId": "ab50c9cd-5b14-442b-c44c-eb1c3f37897e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 37us/sample - loss: 0.3645 - acc: 0.8690\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3644561621785164, 0.869]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tki-Aro_Uax",
        "colab_type": "text"
      },
      "source": [
        "Мне  показало точность около 0,8838, что означает около 88%. Как и ожидалось, модель, вероятно, не будет так хороша с *незнакомыми* данными, как она была с данными, на которых была обучена! Проходя этот курс, вы будете искать способы улучшить ее.\n",
        "\n",
        "Чтобы узнать больше, попробуйте следующие упражнения:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htldZNWcIPSN",
        "colab_type": "text"
      },
      "source": [
        "# Исследовательские упражнения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rquQqIx4AaGR",
        "colab_type": "text"
      },
      "source": [
        "###Упражнение 1:\n",
        "Запустите приведенный ниже код: он классифицирует каждое изображение из тестового набора, а затем печатает первую запись. Вывод метода **model.predict** - это список чисел. Как вы думаете, почему это так, и что представляют собой эти цифры?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyEIki0z_hAD",
        "colab_type": "code",
        "outputId": "97ecb019-7893-4c83-fca1-32860ca2d930",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5.5038083e-07 7.7225003e-08 3.8026219e-06 1.1930431e-06 2.2218392e-06\n",
            " 1.4544085e-03 4.7618842e-06 3.6073010e-02 1.1149858e-05 9.6244884e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdzqbQhRArzm",
        "colab_type": "text"
      },
      "source": [
        "Подсказка: попробуйте вывести значение (test_labels [0]) - и вы получите 9. Это поможет вам понять, почему этот список выглядит так, как он выглядит."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnBGOrMiA1n5",
        "colab_type": "code",
        "outputId": "f9da4d01-5c88-485b-cdbd-b9702a539ae2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(test_labels[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUs7eqr7uSvs",
        "colab_type": "text"
      },
      "source": [
        "На следующие вопросы необходимо ответить [в лекции](http://moodle.asu.edu.ru/mod/lesson/view.php?id=74147&pageid=1625)\n",
        "###  Вопрос 1. Что представляет собой этот список?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD4kC6TBu-69",
        "colab_type": "text"
      },
      "source": [
        "### Вопрос 2. Как вы узнали из этого списка, что предмет - ботинок?\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgQSIfDSOWv6",
        "colab_type": "text"
      },
      "source": [
        "##Упражнение 2:\n",
        "Давайте теперь посмотрим на слои в вашей модели. Экспериментируйте с различными значениями для слоя с 512 нейронами. Какие разные результаты вы получаете для Loss, времени тренировки и т.д.? Как вы думаете, почему?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSZSwV5UObQP",
        "colab_type": "code",
        "outputId": "613b8e52-2916-45a6-fdc4-d88e787cf941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0-rc3\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Train on 60000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 15s 250us/sample - loss: 0.1863\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 15s 248us/sample - loss: 0.0749\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 15s 243us/sample - loss: 0.0471\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 15s 248us/sample - loss: 0.0340\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 14s 239us/sample - loss: 0.0265\n",
            "10000/10000 [==============================] - 1s 102us/sample - loss: 0.0685\n",
            "[6.1148842e-09 2.5392909e-08 2.0338616e-08 1.2911693e-05 1.5519286e-13\n",
            " 8.4710815e-11 1.1122753e-11 9.9998701e-01 2.1595430e-10 7.4157555e-08]\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOOEnHZFv5cS",
        "colab_type": "text"
      },
      "source": [
        "###Вопрос 3. Увеличьте количество нейронов в слое до 1024. Как это повлияет на время обучения и точность?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtWxK16hQxLN",
        "colab_type": "text"
      },
      "source": [
        "##Упражнение 3: \n",
        "\n",
        "Что произойдет, если вы удалите слой Flatten()? Почему вы думаете, что это так?\n",
        "\n",
        "Вы получаете ошибку о форме данных. Это подтверждает практическое правило, что первый слой в вашей сети должен иметь ту же форму, что и ваши данные. Изначально наши данные представляют собой изображения 28x28, и 28 слоев из 28 нейронов были бы неосуществимы, поэтому имеет смысл «расплющить» эти квадраты 28 х 28 в строки 784x1. Вместо того, чтобы писать код для такой обработки, мы добавляем слой Flatten() в начале, и когда потом массивы загружаются в модель, они автоматически вытягиваются для нас в вектор.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExNxCwhcQ18S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "831ce994-af35-4b08-b073-4a0857cd9d55"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([#tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0-rc3\n",
            "Train on 60000 samples\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-cd0411f1d295>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m               loss = 'sparse_categorical_crossentropy')\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: logits and labels must have the same first dimension, got logits shape [896,10] and labels shape [32]\n\t [[{{node loss_2/output_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqoCR-ieSGDg",
        "colab_type": "text"
      },
      "source": [
        "##Упражнение 4:\n",
        "Рассмотрим финальные (выходные) слои. Почему их 10? Что произойдет, если бы у вас было количество, отличное от 10? Например, попробуйте тренировать сеть с 5\n",
        "\n",
        "Вы получаете сообщение об ошибке, как только оно находит неожиданное значение. Еще одно практическое правило - количество нейронов в последнем слое должно соответствовать количеству классов, на которые вы классифицируете. В данном случае это цифры 0-9, поэтому их 10, поэтому в последнем слое должно быть 10 нейронов\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMckVntcSPvo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "3421e241-4e7a-4fb6-ee0e-faae86551dc4"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(5, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0-rc3\n",
            "Train on 60000 samples\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-04e5ea87fa1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m               loss = 'sparse_categorical_crossentropy')\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Received a label value of 9 which is outside the valid range of [0, 5).  Label values: 3 1 5 8 1 7 3 5 6 8 1 4 9 3 8 5 1 2 5 4 8 8 8 7 4 7 7 3 7 1 4 6\n\t [[{{node loss_3/output_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0lF5MuvSuZF",
        "colab_type": "text"
      },
      "source": [
        "##Упражнение 5:\n",
        "\n",
        "Рассмотрим влияние дополнительных слоев в сети. Что произойдет, если вы добавите еще один слой между слоем с 512 и последним слоем с 10.\n",
        "\n",
        "Ответ: Это не оказывает существенного влияния, потому что это относительно простые данные. Для гораздо более сложных данных (включая цветные изображения, на которых нужно классифицировать цветы, которые вы увидите на следующем уроке), часто необходимы дополнительные слои."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1YPa6UhS8Es",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "0fb4ebe2-f33d-41fd-b626-f028a9e43788"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0-rc3\n",
            "Train on 60000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 13s 222us/sample - loss: 0.1829\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 13s 225us/sample - loss: 0.0807\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 13s 224us/sample - loss: 0.0564\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 14s 225us/sample - loss: 0.0416\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 14s 228us/sample - loss: 0.0327\n",
            "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0754\n",
            "[1.11150915e-11 6.96973090e-10 5.67605944e-08 5.23195132e-09\n",
            " 8.12273155e-13 1.06071671e-11 4.02686714e-14 9.99999881e-01\n",
            " 6.88530569e-12 6.26558077e-08]\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE7PDe6LWAHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bql9fyaNUSFy",
        "colab_type": "text"
      },
      "source": [
        "##Упражнение 6:\n",
        "Рассмотрим влияние обучения для большего или меньшего числа эпох. Как вы думаете, почему это так?\n",
        "\n",
        "Попробуйте 15 эпох - вы, вероятно, получите модель с гораздо лучшим Loss, чем модель с 5\n",
        "Попробуйте 30 эпох - вы можете увидеть, что значение потерь перестает уменьшаться, а иногда и увеличивается. Это побочный эффект, называемого «overfitting» или переобучение, за которым нужно следить при обучении нейронных сетей. Нет смысла тратить время на тренировки, если вы не улучшаете свои потери.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE3esj9BURQe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5b624540-3dda-4ccb-8e5e-73c18c98a8e1"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=30)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[34])\n",
        "print(test_labels[34])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0-rc3\n",
            "Train on 60000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.2549\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.1119\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.0765\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.0572\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0450\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.0336\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0274\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0226\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0189\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0151\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0133\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0102\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0102\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0084\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.0091\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.0069\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0060\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0073\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0039\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0061\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0048\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0046\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0056\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0037\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0052\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0043\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0048\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0042\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0033\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0044\n",
            "10000/10000 [==============================] - 0s 46us/sample - loss: 0.1297\n",
            "[1.7468104e-25 7.7016133e-26 1.5919356e-15 4.8122452e-14 3.0398927e-34\n",
            " 9.8379180e-29 4.3248689e-31 1.0000000e+00 2.6073728e-16 2.9930913e-21]\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS3vVkOgCDGZ",
        "colab_type": "text"
      },
      "source": [
        "##Упражнение 7:\n",
        "\n",
        "Перед тренировкой вы нормализовали данные, перейдя от значений 0-255 к значениям 0-1. Как повлияет удаление нормализации? Вот полный код, чтобы попробовать. Как вы думаете, почему получаются разные результаты? Ответьте несколькими предложениями в лекции."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDqNAqrpCNg0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "5076f140-1fce-4903-f007-d2144677b383"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images/1.0\n",
        "test_images=test_images/1.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "model.evaluate(test_images, test_labels)\n",
        "classifications = model.predict(test_images)\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0-rc3\n",
            "Train on 60000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 10s 165us/sample - loss: 2.7759 - acc: 0.9059\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 9s 157us/sample - loss: 0.3329 - acc: 0.9382\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 10s 159us/sample - loss: 0.2989 - acc: 0.9413\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 10s 159us/sample - loss: 0.2757 - acc: 0.9452\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 9s 157us/sample - loss: 0.2426 - acc: 0.9509\n",
            "10000/10000 [==============================] - 1s 87us/sample - loss: 0.3458 - acc: 0.9435\n",
            "[0.0000000e+00 2.1740563e-18 9.4643328e-26 1.2476242e-15 5.4874043e-27\n",
            " 7.4531838e-36 0.0000000e+00 1.0000000e+00 3.3315732e-32 2.6247717e-20]\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7W2PT66ZBHQ",
        "colab_type": "text"
      },
      "source": [
        "##Упражнение 8:\n",
        "Ранее, во время тренировки с дополнительными эпохами, возникла проблема, из-за которой значение Loss могло ухудшиться. Возможно, это заняло некоторое лишнее время, и вы, возможно, подумали: «Разве не было бы хорошо, если бы я мог остановить обучение, когда достигну желаемого значения?» - то есть 95% точности может быть достаточно для вас, и если вы достигнете этого после 3 эпох, зачем сидеть сложа руки в ожидании, пока завершится большое количество эпох.\n",
        "Так как бы вы это исправили? Как и в любой другой программе - у вас есть callback! Посмотрим на них в действии:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkaEHHgqZbYv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "fd10e5c1-da19-4c1f-ab90-57dcacc8c16d"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('loss')<0.4):\n",
        "      print(\"\\nReached 60% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images/255.0\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])\n",
        "\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0-rc3\n",
            "Train on 60000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 9s 154us/sample - loss: 0.4761\n",
            "Epoch 2/5\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.3605\n",
            "Reached 60% accuracy so cancelling training!\n",
            "60000/60000 [==============================] - 9s 148us/sample - loss: 0.3605\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff08dddf278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    }
  ]
}